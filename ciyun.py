#!/usr/bin/env python
# -*- coding:UTF-8 -*-# å¯¼å…¥æ‰©å±•åº“
import re # æ­£åˆ™è¡¨è¾¾å¼åº“
import collections # è¯é¢‘ç»Ÿè®¡åº“
import numpy as np # numpyæ•°æ®å¤„ç†åº“
import jieba # ç»“å·´åˆ†è¯
import wordcloud # è¯äº‘å±•ç¤ºåº“
from PIL import Image # å›¾åƒå¤„ç†åº“
import matplotlib.pyplot as plt # å›¾åƒå±•ç¤ºåº“

# è¯»å–æ–‡ä»¶
fn = open('article.txt','r',encoding='UTF-8') # æ‰“å¼€æ–‡ä»¶
string_data = fn.read() # è¯»å‡ºæ•´ä¸ªæ–‡ä»¶
fn.close() # å…³é—­æ–‡ä»¶

# æ–‡æœ¬é¢„å¤„ç†
pattern = re.compile(u'\t|\n|\.|-|:|;|\)|\(|\?|"') # å®šä¹‰æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æ¨¡å¼
string_data = re.sub(pattern, '', string_data) # å°†ç¬¦åˆæ¨¡å¼çš„å­—ç¬¦å»é™¤

# æ–‡æœ¬åˆ†è¯
seg_list_exact = jieba.cut(string_data, cut_all = False) # ç²¾ç¡®æ¨¡å¼åˆ†è¯
object_list = []
remove_words = [u',', u'time',u'{', u'}', u'text', u'ago', u'author',u'cid',u'months',u'years',u':',u' ',u'.',u'1',u'2',u'month',
                u'year',u'the',u'to',u'and',u'\\',u'!',u'is',u'of',u'"',u'_',u'in',u'you',u'a',u'are',u's',u'that',u'I',u'for',u'/',
                u'n',u'@',u'it',u'from',u'not',u't',u'with',u'have',u'they',u'on',u'ğŸ˜‚',u'your',u'will',u'all',u'be',u'as',u'this',
                u'The',u'can',u'like',u'3',u'about',u'by',u'so',u'but',u'know',u'what',u'â€™',u'â€˜',u'do',u' ',u'he',u'or',u'was',u'their',
                u',',u'ï¼Œ',u'more',u'has',u'don',u'edited',u'who',u'me',u'them',u'we',u'no',u'one',u'de',u'You',u'just',u'&',u'at',u'other',
                u'çš„',u'u',u'only',u'china',u'if',u'countries',u'up',u'Ã­',u'why',u'an',u'my',u'out',u'even',u'than',u'very',u'ã€‚',u'there',u'ğŸ‘' ,
                u'how',u'see',u'want',u'go',u'que',u'ã€',u'also',u'any',u'Khan',u'make',u'would',u'4',u'its',u'never',u'r',u'his',u'get',u'because',
                u'many',u'those',u'when',u'That',u'then',u'most',u'still',u'It',u'been',u'ğŸ‘¹',u'ğŸ‘',u'\'',u'i',u'A',u'THE',u'We',u'm',u'He',u'unfir',u'Ugyl6RHEdBX1a5joTB4AaABAg',
                u'nJRMbG0Ore',u'Ugy9Z',u'YGCLdXlmmhS1x4AaABAg',u'nFt',u'PGgmFw',u're',u'too',u'Ã¡',u'am',u'us',u' ï¼‹',u'And',u'CHINA',u'This',u'O7',u'some',u'ing',
                u'Muhamad',u'Arole',u'Flynn',u'chinese',u'Baloch',u'SKJP',u'Sanky',u'en',u'Aiman',u'But',u'same',u'Ã©',u'If',u'la',u'Leow',u'JS',u'S',u'these',u'\xa0',u'Why']# è‡ªå®šä¹‰å»é™¤è¯åº“

for word in seg_list_exact: # å¾ªç¯è¯»å‡ºæ¯ä¸ªåˆ†è¯
    if word not in remove_words: # å¦‚æœä¸åœ¨å»é™¤è¯åº“ä¸­
        object_list.append(word) # åˆ†è¯è¿½åŠ åˆ°åˆ—è¡¨

# è¯é¢‘ç»Ÿè®¡
word_counts = collections.Counter(object_list) # å¯¹åˆ†è¯åšè¯é¢‘ç»Ÿè®¡
word_counts_top10 = word_counts.most_common(75) # è·å–å‰10æœ€é«˜é¢‘çš„è¯
print (word_counts_top10) # è¾“å‡ºæ£€æŸ¥

# è¯é¢‘å±•ç¤º
mask = np.array(Image.open('wordcloud.jpg')) # å®šä¹‰è¯é¢‘èƒŒæ™¯
wc = wordcloud.WordCloud(
    font_path='C:/Windows/Fonts/Arial.ttf', # è®¾ç½®å­—ä½“æ ¼å¼
    mask=mask, # è®¾ç½®èƒŒæ™¯å›¾
    max_words=75, # æœ€å¤šæ˜¾ç¤ºè¯æ•°
    max_font_size=233, # å­—ä½“æœ€å¤§å€¼
    width=1920,
    height=1080,
    background_color=(255,255,255)
)

wc.generate_from_frequencies(word_counts) # ä»å­—å…¸ç”Ÿæˆè¯äº‘
image_colors = wordcloud.ImageColorGenerator(mask) # ä»èƒŒæ™¯å›¾å»ºç«‹é¢œè‰²æ–¹æ¡ˆ
wc.recolor(color_func=image_colors) # å°†è¯äº‘é¢œè‰²è®¾ç½®ä¸ºèƒŒæ™¯å›¾æ–¹æ¡ˆ
plt.imshow(wc) # æ˜¾ç¤ºè¯äº‘
plt.axis('off') # å…³é—­åæ ‡è½´
plt.savefig("temp.png",dpi=500,bbox_inches = 'tight')
plt.show() # æ˜¾ç¤ºå›¾åƒ
plt.close()

